{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: Obtaining and Wrangling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is loosely inspired on Jake van der Plas, Python Data Science Handbook, [Chapter 3 Section 6](https://jakevdp.github.io/PythonDataScienceHandbook/03.06-concat-and-append.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "**Before** you start (and open this Notebook):\n",
    "- Make a new folder with the name 'lecture3' and move the Notebook to this folder\n",
    "- In this 'lecture3' folder you've just created, make a subfolder with the name 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Downloading Social Media Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lecture, you learned how to load data from an online repository. Pandas is smart enough to directly download and read a CSV file from a given URL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: \n",
    "\n",
    "Load the data [here](https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/data/page_5281959998_2018_12_28_22_00_39_fullstats.tab) into you Notebook and print the first ten rows.\n",
    "\n",
    "- Before we start we have load Pandas, do you remember how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load Pandas using pd as a shorthand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then load the data as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how to **(a)** download the data and **(b)** read it from disk? Please follow these steps:\n",
    "- Go to the DMI [YouTube toolbox](https://tools.digitalmethods.net/netvizz/youtube/). \n",
    "- Scroll down to \"Video Info and Comments\" and click **launch**.\n",
    "- Read the information under the \"Video Info and Comments Module\" tab.\n",
    "- Then under the \"Parameters\" tab, copy-paste the id of [this video](https://www.youtube.com/watch?v=v5p-YQkbe_s)\n",
    "> HINT: the video id is the part following **?v=** as in https://www.youtube.com/watch?v=**VIDEOID**\n",
    "- Click \"Submit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wait a few seconds--the tool needs some time to download all comments and replies--you should see, at the bottom of the page, a handful of `.tab` files.\n",
    "- Download the file that ends with **comments.tab**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then copy the file to 'data' folder (yes, the one you created just a few seconds earlier) . If you don't remember where your Notebook is located then run the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below prints the location of the Notebook on your disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below opens this folder in a new Finder window (at least on a Mac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can open the file with Pandas `read_csv()` function. The function requires two arguments\n",
    "- the location of the file we wish to open: as the Notebook and the \"data\" map are in the same folder, we have to instruct Python to start at the current directory (this is done with \"./\" go to the \"data/\" folder and open the file we just downloaded. \n",
    "    - In other words, we should enter something like this './data/<filename.tab> (but replace the last part of the path with the name of the file you just downloaded)\n",
    "- the character used for separating the cells: in this case, we have to set the \"sep\" argument to \"\\t\" (sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "With the additional explanation, try to open the comments file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "- Download the comments to a video of your own choice and load them into your Notebook as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "- The comments file is just one of the three .tab files. Explore the information in the other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information, or if things remain unclear, watch the video below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('sbErTW2MzCY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Facebook Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading information from Facebook\n",
    "\n",
    "To use Netvizz, you first need to install [this application](https://apps.facebook.com/107036545989762/). (Un)Fortunately (depending on your view) you cannot download information from individual users, only public pages are accessible via Netvizz. The tool allows you to download posts by the page itself and the reactions to these posts. \n",
    "\n",
    "We will extract posts and comments from the [New York Times'Facebook page](https://www.facebook.com/nytimes/).\n",
    "\n",
    "- After installing Netvizz, click on \"page posts\"\n",
    "- Enter the page id (this can be found [here](http://lookup-id.com/))\n",
    "- Under \"date scope\" select last 100 posts\n",
    "- Under \"data to get\" select \"post statistics and 200 top ranked comments per post\"\n",
    "- Lastly, select posts \"by page only\"\n",
    "\n",
    "Again, wait a few seconds. Some visualisations are generated, once this is done, you should be able to click on \"Download the data as zip archive\" at the bottom of the page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise \n",
    "\n",
    "Move the zip archive to the folder we created at the start of this lecture. Unzip its contents and try to open the comments file.\n",
    "> HINT: Use tab-completion to make things easier. In the expression below (`path = '.'`) put your cursor after the dot just before the last quotation mark, and press `tab` on your keyboard. This should open a box with suggestions and guide you to the correct folder and filename (so you do not have to type everything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path ='.'\n",
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\* Exercise:\n",
    "\n",
    "- Download 100 posts by a right-wing media outlet (such as Fox News)\n",
    "- Compute the mean for the `rea_ANGRY` column, both for the New York Times and the right-wing page you download. \n",
    "\n",
    "Are users on right-wing pages on average more angry than those on left-wing pages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case downloading the files is impossible, proceeds with these data.\n",
    "- [New York Times data](https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/lecture_3_data/nytimes.tab)\n",
    "- [Fox News](https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/lecture_3_data/foxnews.tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Manipulating and Creating New Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with the preceding analysis is the fact that we only look at the absolute counts: if one page simply has more users and activity than the other, the result for the angry reactions will be higher anyway. We could instead compare the percentage of angry reactions per post. In Pandas we can do this easily by creating a new column that computes the percentage of angry reactions per post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows how to compute percentages using a toy-example: it lists apples, pears and the total number of fruits in a basket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([[1,2,12],[3,4,14],[3,5,10]],columns=['apples','pears','total_fruit'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the percentage of apples we create a new column with the name 'apples_percentage'. The percentage is the number of apples divided by the total fruits in our basket, and this number is multiplied by a hundred.\n",
    "> Notice the use of parentheses in this example. This determines the [operator precedence](https://www.tutorialspoint.com/python/operators_precedence_example.htm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['apples_percentage'] = (data['apples'] / data['total_fruit'] )*100\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise \n",
    "\n",
    "Make a new column which is equal to the sum of the apples and the pears. Give this column the name \"apples_pears_summed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise.\n",
    "\n",
    "Now let's compare angriness across pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can sum all the angry reactions. The code below shows how to do this for data we worked with in the previous lecture. Replicate the example below with your own data (i.e. load them from disk and, sum all the angry reactions and divide this number by the total number of reactions). What do these numbers tell you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of angry reactions 29955\n",
      "Total number of angry reactions 118734\n",
      "Ratio of angry reactions 0.2522866238819546\n",
      "29955\n"
     ]
    }
   ],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "# load data\n",
    "example_data = pd.read_csv('https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/data/page_5281959998_2018_12_28_22_00_39_fullstats.tab',sep='\\t')\n",
    "# compute sum of all the angry reactions\n",
    "angry = example_data['rea_ANGRY'].sum()\n",
    "# print this number\n",
    "print('Total number of angry reactions',angry)\n",
    "# compute the total sum of all reactions\n",
    "total_reactions = example_data['reactions_count_fb'].sum()\n",
    "print('Total number of angry reactions',total_reactions)\n",
    "# the ratio is the sum of all angry reactions divided by\n",
    "# the sum of all reactions\n",
    "ratio = angry/total_reactions\n",
    "print('Ratio of angry reactions',ratio)\n",
    "print(angry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now apply this code example to your own data and compute the ratio of angry reactions for the left and the right-wing corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Scenario\n",
    "\n",
    "The section below explores a common research scenario. We compare the behaviour of two groups (of users). More specifically we investigate if right and left-wing audiences exhibit different behaviour with respect to how they react to Social Media content. The goal of this scenario is to compare summary statistics and distributions. Put simply, let's look who gives more love online!\n",
    "\n",
    "First, we load posts from the New York Times and Fox News (you can use your own data later, for now, I suggest you work with the prepared CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_right = pd.read_csv('https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/lecture_3_data/foxnews.tab',sep='\\t')\n",
    "df_left = pd.read_csv('https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/lecture_3_data/nytimes.tab',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the number of rows and columns in these DataFrames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the ratio of LOVE reactions on the New York Times page, we create a new column with the name 'ratio_love_left' which is equal to love reactions divided by the total reactions.\n",
    "- divide the column 'rea_LOVE' by 'reactions_count_fb'\n",
    "- use `/` for division\n",
    "- inspect the the toy example above if you forgot how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for Fox News, name the new column 'ratio_love_right'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To investigate if the ratios are different, we can, as a first step, look at some general statistics using `.describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_left['ratio_love_left'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `.describe()` to the right-wing souce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Compare these numbers? Is there more love on the left or on the righ?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# write answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the **distribution** of the love reactions (or more exactly the distribution of the ratios). We use the density plot, which is \"a smoothed, continuous version of a histogram estimated from the data.\" Source and more information [here](https://towardsdatascience.com/histograms-and-density-plots-in-python-f6bda88f5ac0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_left['ratio_love_left'].plot(kind='density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice Notebook feature, is that we can overlay the distribution plots and compare them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df_left['ratio_love_left'].plot(kind='density',legend=True)\n",
    "df_right['ratio_love_right'].plot(kind='density',legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Inspect the distribution. To what exten do they provide an answers to the initial research question?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# write answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Additional**:\n",
    "\n",
    "We can perform the [Student's t-test](https://en.wikipedia.org/wiki/Student%27s_t-test) to compute whether the means are statistically different. If the p-value is smaller than 0.05 they are, otherwise not! A good introduction to inferential statistic is available on [Khan Academy](https://www.khanacademy.org/math/statistics-probability). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "ttest_ind(df_left['ratio_love_left'],df_right['ratio_love_right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  \\*\\*\\*Exercise\n",
    "\n",
    "What about angry reactions? Replicate the preceding analysis, and study whether audiences on the right are more angry then those on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Combining DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the previous Notebook focussed on manipulating individual DataFrames, the remainder of this lecture will focus on combining DataFrames: instead of investigating just one YouTube video or Facebook page, we can combine and merge information from different sources (for example comments on multiple youtube videos). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.concat()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.concat` can be used for concatenating two `pd.DataFrame` objects. To understand how this works, we first explore a simple example, before applying it to real-world data.\n",
    "\n",
    "First, we make a 2 x 2 matrix with the integer 1, 2, 3, 4 and columns \"A\" & \"B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([[1,2],[3,4]],columns=['A','B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Make two more 2 x 2 DataFrames. You can choose the values yourself, but one DataFrame has to have \"A\" & \"B\" as columns names, the other one \"C\" & \"D\". Assign the former to a variable with the name `df2`, the latter to a variable with the name `df3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect all the arguments of `pd.concat()`  use Python's in-built `help()` function.\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Print the documentation on `pd.concat()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# search for help by putting pd.concat between the brackets of the help function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To join two DataFrames you have to pass them as a list to the `pd.concat()` function, like this (note the square brackets around `df1` and `df2`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `pd.concat()` concatenates the DataFrame row-wise (i.e. the `axis` attribute is set by default to zero, as you see in the above documentation). If you'd like to join them column-wise, you have to set the `axis` argument to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df1,df2],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "- concatenate df2 and df3 row-wise.\n",
    "- concatenate df2 and df3 column-wise.\n",
    "- concatenate df1 and df3 column-wise. What do you think `NaN` means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you notice, when concatenating `df1` and `df2` row-wise, the index is repeated. In many situations, this is not ideal, as the index and columns are used to uniquely identify each cell in the DataFrame. If the indices are not of intrinsic value we can simply ignore them by the setting the `ignore_index` argument to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df1,df2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the index ranges from 0 to 3 instead of repeating 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise \n",
    "\n",
    "Concatenate all three DataFrames. What are the dimensions of the eventual DataFrame? \n",
    "> HINT: use the `.shape` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\* Exercise:\n",
    "\n",
    "Let's analyse the reception of John Oliver's \"Last Week Tonight\" Download the comments to the video on [Rudi Giuliani](https://www.youtube.com/watch?v=mXQuto1fMp4), and on [Ivanka Trump and Jard Kushner](https://www.youtube.com/watch?v=wD8AwgO0AQI).\n",
    "\n",
    "- Download the comments;\n",
    "- Open both files with `pd.read_csv` (use `df1` and `df2` as variable names);\n",
    "- Concatenate both dataframes, assign them to the variable `df3`\n",
    "- What are dimensions of this DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything went well, the line below should return `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.shape[0] + df2.shape[0] == df3.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging DataFrames\n",
    "\n",
    "`pd.concat()` is useful when concatenating DataFrames that have the same columns--we basically just enlarge our dataset by adding rows together from sources that have the same structure. However, in many situations, we'd like to combine different types of information. \n",
    "\n",
    "As in the above section (on concatenation) we first inspect some toy examples before turning to a realistic scenario, this time based on Facebook data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function we will be working with is `pd.merge`, again we can use `help()` to inspect the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# search for help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A classic example for merging tables is the **one-to-one** join. This scenario is similar to concatenation. Imagine we have information on a company's employees, in different files. The example code below generates two DataFrames, one recording the employee's function, the other the hire date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'function': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Create another dataframe (`df_salary`), recording the salary of the these employees--of course you can invent the amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we merge these DataFrames by employee we get the following result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.merge(df2,on='employee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `on` argument specifies the column on which to join the DataFrames. In this case, Pandas would have been smart enough recognize that the DataFrames share an 'employee' column on which they can be joined. However, it is always safer to explicitly tell Pandas which column it should use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df1.merge(df2,on='employee')\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "Merge `df3` and the `df_salary` DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another situation is the **many-to-one** join: \n",
    "\n",
    "\"Many-to-one joins are joins in which one of the two key columns contains duplicate entries\" (From Jake van der Plas)\n",
    "\n",
    "An example is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>supervisor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>Carly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>Guido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR</td>\n",
       "      <td>Steve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group supervisor\n",
       "0   Accounting      Carly\n",
       "1  Engineering      Guido\n",
       "2           HR      Steve"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],\n",
    "                    'supervisor': ['Carly', 'Guido', 'Steve']})\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df1.merge(df2,on='employee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see the supervisor row with Guido (in `df4`) is mapped to many rows in `df3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only covered the tip of the iceberg here. There is a lot more to this type of operations. If you like to know more, please read [this section](https://jakevdp.github.io/PythonDataScienceHandbook/03.07-merge-and-join.html) in Jake van der Plas, [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/). However, we know enough to start working with some real data. Below I will show how to merge Facebook posts with their comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\*Exercise: Merging Facebook data\n",
    "\n",
    "Facebook is a platform where users can directly engage with news media. Below we want to create a database that would allow is to study posts in relation to their comments. Netvizz enables you to download posts and comments seperately. \n",
    "\n",
    "- The folder [`data_nytimes`](https://github.com/kasparvonbeelen/CTH2019/tree/master/data_nytimes) contains a file that ends with 'fullstats.tab'. Open this file with `pd.read_csv`.\n",
    "- Print the dimensions of this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here\n",
    "url_posts = 'https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/data_nytimes/page_5281959998_2018_12_28_22_00_39_fullstats.tab'\n",
    "data_fb_posts = pd.read_csv(url_posts,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fb_posts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the DataFrame\n",
    "- Print the column names\n",
    "- Print the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, open the `.tab` file with the [comments](https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/data_nytimes/page_5281959998_2018_12_28_22_00_39_comments.tab) and inspect the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: which columns, do you think, should we use to merge the two dataframes?\n",
    "> Hint: I suggest `post_id`\n",
    "\n",
    "Merge the two dataframes, assigned this result to a variable with the name `combined`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If everything worked well, the line below should return `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined.shape[0] == data_fb_comments.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\* Open Exercise\n",
    "\n",
    "By now you know how to\n",
    "- Retrieve Social Media Data\n",
    "- Combine information\n",
    "- and make comparisons\n",
    "\n",
    "In this last exercise, you will expand the left-right comparison we performed above. Instead of just comparing the New York Times with Fox News, you will\n",
    "- download information from various left- or right-wing media platforms (at least two for each side, but preferably more)\n",
    "- merge the retrieved .tab files into larger DataFrames (one for left-wing media, one for right-wing media)\n",
    "- compare the distribution of various reaction types.\n",
    "- write a short report, just 100 hundred words, about your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# write report here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations, you made it to the end of the lecture 3!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
