{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Grouping and Making Comparisons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Research Scenario: Content Type and Popularity\n",
    "\n",
    "Are posts with pictures more popular than other types of content? To answer this question we have to compare the content type in relation to the likes they receive. The code below shows how to do this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Load posts by the comedian [Andy Borowitz](https://www.facebook.com/andyborowitz/). Data is [here](https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/data/page_38423635680_2019_01_13_12_33_40.tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/data/page_38423635680_2019_01_13_12_33_40.tab'\n",
    "data = pd.read_csv(url,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Print the column names and the first ten rows. Which column contains information about the post's content type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `.unique()` method to this column to see which values the column contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the \"type\" column lists indicates if the post contained a picture or not. With Pandas we can easily study whether, on average, posts with pictures receive more reactions than other content types. Run the code, later on, I will explain how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_means = data.groupby('type')['reactions_count_fb'].mean()\n",
    "group_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A visual represention is often more insightful, so let's make a barplot to compare the means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "group_means.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the actual distribution is also possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.groupby('type')['reactions_count_fb'].plot(kind='density',legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About `.groupby()`\n",
    "\n",
    "Ok, what happened here?\n",
    "\n",
    "Basically, the `.groupby()` function groups the table by the column selected within the parentheses (here different content types, e.g. \"link\", \"photo\" etc.). Then for each group, we apply a specific calculation (e.g. computing the average or simply summing all the values). The figure below gives a good graphic representation of this process. The only difference is that we used the `.mean()` instead of `.sum()`.\n",
    "<img src=\"http://i0.wp.com/datapandas.com/wp-content/uploads/2016/09/pandas-powerful-data-analysis-tools-group-by.jpg?resize=600%2C450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, `.groupby()` divides the DataFrame by a specific category and then applies a method (such as sum, median or other) to each of these sub-tables before combining the tables again. To see how this works you can inspect the toy example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = pd.DataFrame([['A',1],['B',2],['A',4],['B',1],['A',6],['B',1]],columns=['category','value'])\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below we group results by the \"category\" and then sums (for each of the sub-tables) the values in the \"value\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example.groupby('category')['value'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Group by the \"category\" column and then compute the mean of 'value'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Returning to the Borowitz example: The results suggested that, on average, posts with pictures are more popular. But, as seen in lecture 2, the mean is sensitive to outliers. To check if the results are robust, investigate if the findings change when computing the median by content type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Does visual content elicit stronger *emotional* responses? Inspect the angry and love reactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\* Exercise\n",
    "\n",
    "We can use a similar technique to track the most active users on  Social Media platforms. \n",
    "- Load comments on the YouTube Techno Documentary we studied in the second lecture (you can use [this table](https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/data/videoinfo_-OLEyOYC6P4_2018_12_18-09_26_24_comments.tab))\n",
    "- Group the table by users (use \"authorName\")\n",
    "- Then apply `count()` to the \"id\" column\n",
    "- Assign the result of this operation to a new variable `df_comment_count`\n",
    "- Sort this DataFrame in descending order by applying the `.sort_values()` method to `df_comment_count` \n",
    "- In the latter method, set the `ascending` argument to `False` (i.e. .`sort_values(ascending=False)`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\* Exercise\n",
    "\n",
    "- Continuing the Youtube Techno example: Can you also rank the authors by the likes they have **received** (i.e. find the most popular authors). Save the result of the `.groupby()` operation in a new variable with the name `df_like_count`\n",
    "\n",
    "> HINT: first group by authorName and then apply `sum()` to the likeCount\n",
    "\n",
    "- Plot the distribution of these likes (grouped by author) with a Histogram or a Density plot. These follow a winner-takes-it-all [Power Law](https://en.wikipedia.org/wiki/Power_law)\n",
    "\n",
    "> HINT: simply apply `.plot(kind='density'`) to `df_like_count`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Research Scenario: Lexicon-Based Sentiment Analysis with VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding examples we relied on reactions to study emotional behaviour on social media. Oftentimes, this information is not available, and we only have access the text itself to detect emotion. In this situation we can use automatic sentiment detection tools such as **VADER**.\n",
    "\n",
    "[from Github](https://github.com/cjhutto/vaderSentiment): VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool.\n",
    "\n",
    "VADER uses a [lexicon](https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt) (a mapping of words to sentiment values, e.g bad=-1.0, good=+1.0) to compute the sentiment (positivity or negativity) of a text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "Inspect the VADER lexicon: Can you understand the structure of this table? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# write answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before working with VADER we first have to check if NLTK is properly installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if this cell yields an error run the next one\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only run this cell if the preceding one yields an error\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run VADER, we need to install the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need to install the vader lexicon first\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load and initialize the VADER Sentiment analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment import vader\n",
    "analyzer = vader.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can test VADER yourself by changing the value of the ``text`` variable, and running the code block. \n",
    "\n",
    "Can you trick the system? Not very easy isn't it?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"Not interesting.\"\n",
    "sentiments_analysis = analyzer.polarity_scores(text)\n",
    "print(sentiments_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Copy-paste the code above, but change the `text` variable and inspect the emotion scores VADER produces (try typing a very positive and a very negative sentence). Also, try to fool VADER by writing complex sentences with negations (such as \"not sad\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested here in the compound emotion, a combination of positive and negative sentiment. We can select this specific value by putting the string 'compound' between square brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiments_analysis['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can things a make easier, by writing a function that does this at once, i.e. return the compound score given a text. Just run the cell below, don't worry about the syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this cell to create the function\n",
    "def compound_sentiment(text):\n",
    "    sentiments_analysis = analyzer.polarity_scores(str(text))\n",
    "    return sentiments_analysis['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_text = \"This is sooooo not funny!\"\n",
    "compound_sentiment(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compound_sentiment` takes a text and returns the compound sentiment computed by VADER. This technique allows us to study emotional behaviour online, based on the posts users write.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the data in a DataFrame we can easily apply the `compound_sentiment` function to **all** comments. For such an operation--applying a function to all rows in a DataFrame--Pandas offers the `.apply()` method. In the cells below, we will investigate emotion in comments on the New York Times' Facebook page.\n",
    "\n",
    "So let's load the data again. By now, you should know how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/data_nytimes/page_5281959998_2018_12_28_22_00_39_comments.tab'\n",
    "# insert code here\n",
    "df = pd...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first try to compute sentiment present in the **posts** (instead of the comments). Look attentively at the syntax below. \n",
    "\n",
    "- `df['post_text']`: selects the column we want to use for sentiment mining\n",
    "- .apply(compound_sentiment): apply the function between the paranthesis to this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['post_emotion'] = df['post_text'].apply(compound_sentiment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\*Exercise\n",
    "\n",
    "Plot a histogram that visualises the distribution of the emotion scores returned by VADER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average emotion score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply `compound_emotion` to the **comments** (above we applied it only to the posts). Save these scores in a new column `comment_emotion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of these emotion scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the average post more negative than the average comment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Research Scenario: Finding the Haters (and Lovers?)\n",
    "\n",
    "In this scenario, we aim to investigate online harrasment by identifying users who comment frequently *and* in a negative way. I selected comments from on an interview with [Taylor Swift](https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/data/videoinfo_P-TFhUq3otQ_2019_01_15-11_21_20_comments.tab). Run the example, and replicate the scenario using a video of your own choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/data/videoinfo_P-TFhUq3otQ_2019_01_15-11_21_20_comments.tab'\n",
    "dfcomment=pd.read_csv(url,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below contains a function to identify only the **negative** sentiment present in a post. After running the cell (and loading it into memory) we can apply it to all the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def negative_sentiment(text):\n",
    "    sentiments_analysis = analyzer.polarity_scores(str(text))\n",
    "    return sentiments_analysis['neg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Change the text variable below, to undestand how `negative_sentiment` works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = 'TYPE YOU TEXT HERE'\n",
    "negative_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcomment['negative_emotion'] = dfcomment['text'].apply(negative_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you print the first 10 rows, you'll see that the DataFrame now contains a new colomn that records the negative emotion present in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcomment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can count how often a user posted under this video by counting the number of comment ids by user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = dfcomment.groupby('authorName')['id'].count()\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are only interested in the very active users, we sort the Series in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_sorted = users.sort_values(ascending=False)\n",
    "users_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The `.index` attribute contains the actual name of the users, sorted by the number of comments they posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_sorted.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we only look at the 10 most active users. These we can select by applying the square brackets to the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ten_most_active = users_sorted.index[:10]\n",
    "ten_most_active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have these names, we can select rows where the user name appears in the `ten_most_active` list. In Pandas, we can create a mask with `list1.isin(list2)`. The method `.isin()` checks whether elements from `list1` appear in `list2`. More precisely, which values in the column 'authorName' appear in the `ten_most_active` Series. The cell below prints the rows for which this condition holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcomment['authorName'].isin(ten_most_active)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save rows created by the these most active users in a separate DataFrame. You'll notice that we discard quite some information as most users only post once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_active_users = dfcomment[dfcomment['authorName'].isin(ten_most_active)]\n",
    "df_active_users.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we rely on `.groupby()` to compute the mean of the negative emotion scores (by user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_commenters = df_active_users.groupby('authorName')['negative_emotion'].mean()\n",
    "negative_commenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, and don't forget to sort the users by their negativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_commenters.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `.loc` we can inspect what these users actually wrote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = -1 # ignore this, this is just to print more text\n",
    "print(dfcomment.loc[dfcomment['authorName'] == 'n i c o l e','text'])\n",
    "pd.options.display.max_colwidth = 50 # ignore this, this is just to print more text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\*Exercise\n",
    "\n",
    "Replicate this scenario with a YouTube video of your own choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Research Scenario: Content Analysis and Reactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, we study text in relation to context. Do certain topics elicit more negative reactions than others? Here we look at the perception of Trump on Fox News and the New York Times.\n",
    "\n",
    "But first, we have to revisit the string methods encountered in Lecture 1. There we inspected several string functions, for example `len()` and `.lower()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Count the number of characters in the sentence below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = \"Jeremy Corbyn has pledged Labour will call a no-confidence motion in Theresa May’s government “soon”, while again indicating that if he became prime minister he would prefer to negotiate his own Brexit deal rather than call a second referendum.\"\n",
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, lowercase the sentence and save the lowercased sentence in a new variable `sentence_lower`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Pandas, you can easily apply these functions to a whole text column. Look attentively to the toy example below, before turning towards the main assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_df = pd.DataFrame([[17,'Hello :-)'],[25,'How are you!'],[121,'Yes!'],[10,\"Yihaaaa\"]],columns=['likes','text'])\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`len` records the length of each text.\n",
    "\n",
    "> Notice the use of .str. between the column and the `len()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_df['text'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can add this column to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_df['text_length'] = example_df['text'].str.len()\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a new column that records the length of the values in the text column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\*Exercise \n",
    "\n",
    "- Retrieve comments from the New York Times (or use [these data](https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/data_nytimes/page_5281959998_2018_12_28_22_00_39_comments.tab) I prepared)\n",
    "- Compute the length of each comment; add these values as a new column to the DataFrame\n",
    "- Sort the DataFrame by comment length; print the ten longest comments\n",
    "- Plot the distribution of the comment lengths using a Histogram (set the `bins` attribute to 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\*Exercise \n",
    "\n",
    "Simple question: are posts on the New York Times Facebook page on average longer than those on the Fox News page?  Use the techniques you learned in this and previous lecture to answer this question. You can use these data:\n",
    "- [Fox News](https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/lecture_3_data/foxnews.tab)\n",
    "- [New York Times](https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/lecture_3_data/nytimes.tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides len() and lower() we can also apply `.find()` to text columns in DataFrames. Revisiting the toy example above (`example_df`), let's make a new column that has value one for strings that contain the character `a`, otherwise, the value is zero.\n",
    "\n",
    "First we create a column that has value -1 for strings that do not contain the query term (in this case the character 'a'), otherwise, it records the position of the first hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " example_df['text'].str.find('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below adds this information as a new column to the `example_df` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_df['has_a'] = example_df['text'].str.find('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the values of cells\n",
    "\n",
    "Below we change the value for the 'has_a' column. If the value is bigger than -1 (which means that the row contains the query term) we set the value to 1.\n",
    "\n",
    "> Notice the use of `.loc`. The syntax is similar to selecting a part of a DataFrame using a mask and a column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_df.loc[example_df['has_a'] >= 0,'has_a'] = 1 \n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those rows that do not contain the query term, we set the values to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_df.loc[example_df['has_a'] < 0] = 0\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a similar technique to find posts about Trump from the New York Times. \n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Explain, in a few words, what happens at each line in the code cells below. Use # to comment on the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "url = 'https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/lecture_3_data/nytimes.tab'\n",
    "data_nytimes = pd.read_csv(url,sep='\\t')\n",
    "data_nytimes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_nytimes['about_trump'] = data_nytimes['post_message'].str.find('Trump')\n",
    "data_nytimes['about_trump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_nytimes.loc[data_nytimes['about_trump'] >= 0,'about_trump'] = 1\n",
    "data_nytimes.loc[data_nytimes['about_trump'] < 0,'about_trump'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now \"about_trump\" is a binary variable: 1 for posts that mention Trump, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_nytimes['about_trump']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can investigate if posts about Trump receive more angry reactions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_angry = data_nytimes.groupby('about_trump')['rea_ANGRY'].mean()\n",
    "trump_angry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers are convincing, even more so when we use a visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_angry.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\*What about love for Trump on the New York Times?\n",
    "\n",
    "What about LOVE for Trump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\* Exercise\n",
    "\n",
    "Use the [Fox News Dataset](https://raw.githubusercontent.com/kasparvonbeelen/CTH2019/master/lecture_3_data/foxnews.tab). Do you find a similar pattern when inspecting Love and Hate reactions to Trump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\*\\*\\* Exercise\n",
    "\n",
    "Let's revisit the posts from Andy Borowitz. He become a famous critique of Donald Trump. The exercise explores whether his followers are more reactive to his comments on the president.\n",
    "\n",
    "Similar to the example above:\n",
    "- Create a new column with the name \"lowercased\" which contains the lowercased text\n",
    "- Create a column which records if the post contains the string \"trump\". The column has value 1 if the post text mentions Trump, otherwise it has the value 0.\n",
    "- Use `.groupby()` to compare the average number of **likes** that posts about Trump receive.\n",
    "- Inspect also HAHA, LOVE and ANGRY reactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's all for today! Congratulations again!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
